{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import numpy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fahrenheit 451 by ray bradbury\\nthis one, with gratitude, is for don congdon.\\nfahrenheit 451:\\nthe temperature at which book-paper catches fire and burns\\npart i\\nit was a pleasure to burn\\nit was a special pleasure to see things eaten, to see things blackened and changed. with the brass nozzle in his fists, with this great python spitting its venomous kerosene upon the world, the blood pounded in his head, and his hands were the hands of some amazing conductor playing all the symphonies of blazing and burning to bring down the tatters and charcoal ruins of history. with his symbolic helmet numbered 451 on his stolid head, and his eyes all orange flame with the thought of what came next, he flicked the igniter and the house jumped up in a gorging fire that burned the evening sky red and yellow and black. he strode in a swarm of fireflies. he wanted above all, like the old joke, to shove a marshmallow on a stick in the furnace, while the flapping pigeon-winged books died on the porch and lawn of the house. while the books went up in sparkling whirls and blew away on a wind turned dark with burning.\\nmontag grinned the fierce grin of all men singed and driven back by flame.\\nhe knew that when he returned to the firehouse, he might wink at himself, a minstrel man, burntcorked, in the mirror. later, going to sleep, he would feel the fiery smile still gripped by his face muscles, in the dark. it never went away, that. smile, it never ever went away, as long as he remembered.\\nhe hung up his black-beetle-coloured helmet and shined it, he hung his flameproof jacket neatly; he showered luxuriously, and then, whistling, hands in pockets, walked across the upper floor of the fire station and fell down the hole. at the last moment, when disaster seemed positive, he pulled his hands from his pockets and broke his fall by grasping the golden pole. he slid to a squeaking halt, the heels one inch from the concrete floor downstairs.\\nhe walked out of the fire station and along the midnight '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"FAHRENHEIT 451.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read() \n",
    "raw_text = raw_text.lower()\n",
    "raw_text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '?': 22, '`': 23, 'a': 24, 'b': 25, 'c': 26, 'd': 27, 'e': 28, 'f': 29, 'g': 30, 'h': 31, 'i': 32, 'j': 33, 'k': 34, 'l': 35, 'm': 36, 'n': 37, 'o': 38, 'p': 39, 'q': 40, 'r': 41, 's': 42, 't': 43, 'u': 44, 'v': 45, 'w': 46, 'x': 47, 'y': 48, 'z': 49}\n"
     ]
    }
   ],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  251219\n",
      "Total Vocab:  50\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  251091\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 128\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "  seq_in = raw_text[i:i + seq_length]\n",
    "  seq_out = raw_text[i + seq_length]\n",
    "  dataX.append([char_to_int[char] for char in seq_in])\n",
    "  dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 31, 41, 28, 37, 31, 28, 32, 43, 1, 14, 15, 11, 1, 25, 48, 1, 41, 24, 48, 1, 25, 41, 24, 27, 25, 44, 41, 48, 0, 43, 31, 32, 42, 1, 38, 37, 28, 7, 1, 46, 32, 43, 31, 1, 30, 41, 24, 43, 32, 43, 44, 27, 28, 7, 1, 32, 42, 1, 29, 38, 41, 1, 27, 38, 37, 1, 26, 38, 37, 30, 27, 38, 37, 9, 0, 29, 24, 31, 41, 28, 37, 31, 28, 32, 43, 1, 14, 15, 11, 20, 0, 43, 31, 28, 1, 43, 28, 36, 39, 28, 41, 24, 43, 44, 41, 28, 1, 24, 43, 1, 46, 31, 32, 26, 31, 1, 25, 38, 38, 34, 8, 39, 24, 39, 28, 41, 1]\n"
     ]
    }
   ],
   "source": [
    "print(dataX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(dataY[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0., 1., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2]))) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(y.shape[1], activation='softmax')) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# define the checkpoint \n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-256.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "31387/31387 [==============================] - ETA: 0s - loss: 2.7503\n",
      "Epoch 00001: loss improved from inf to 2.75034, saving model to weights-improvement-01-2.7503-256.hdf5\n",
      "31387/31387 [==============================] - 762s 24ms/step - loss: 2.7503\n",
      "Epoch 2/12\n",
      "31387/31387 [==============================] - ETA: 0s - loss: 2.5498\n",
      "Epoch 00002: loss improved from 2.75034 to 2.54985, saving model to weights-improvement-02-2.5498-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.5498\n",
      "Epoch 3/12\n",
      "31386/31387 [============================>.] - ETA: 0s - loss: 2.4254\n",
      "Epoch 00003: loss improved from 2.54985 to 2.42544, saving model to weights-improvement-03-2.4254-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.4254\n",
      "Epoch 4/12\n",
      "31387/31387 [==============================] - ETA: 0s - loss: 2.3414\n",
      "Epoch 00004: loss improved from 2.42544 to 2.34142, saving model to weights-improvement-04-2.3414-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.3414\n",
      "Epoch 5/12\n",
      "31387/31387 [==============================] - ETA: 0s - loss: 2.2705\n",
      "Epoch 00005: loss improved from 2.34142 to 2.27054, saving model to weights-improvement-05-2.2705-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.2705\n",
      "Epoch 6/12\n",
      "31386/31387 [============================>.] - ETA: 0s - loss: 2.2161\n",
      "Epoch 00006: loss improved from 2.27054 to 2.21608, saving model to weights-improvement-06-2.2161-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.2161\n",
      "Epoch 7/12\n",
      "31387/31387 [==============================] - ETA: 0s - loss: 2.1705\n",
      "Epoch 00007: loss improved from 2.21608 to 2.17050, saving model to weights-improvement-07-2.1705-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.1705\n",
      "Epoch 8/12\n",
      "31386/31387 [============================>.] - ETA: 0s - loss: 2.1312\n",
      "Epoch 00008: loss improved from 2.17050 to 2.13118, saving model to weights-improvement-08-2.1312-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.1312\n",
      "Epoch 9/12\n",
      "31387/31387 [==============================] - ETA: 0s - loss: 2.0975\n",
      "Epoch 00009: loss improved from 2.13118 to 2.09750, saving model to weights-improvement-09-2.0975-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.0975\n",
      "Epoch 10/12\n",
      "31386/31387 [============================>.] - ETA: 0s - loss: 2.0655\n",
      "Epoch 00010: loss improved from 2.09750 to 2.06550, saving model to weights-improvement-10-2.0655-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.0655\n",
      "Epoch 11/12\n",
      "31386/31387 [============================>.] - ETA: 0s - loss: 2.0410\n",
      "Epoch 00011: loss improved from 2.06550 to 2.04092, saving model to weights-improvement-11-2.0409-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.0409\n",
      "Epoch 12/12\n",
      "31387/31387 [==============================] - ETA: 0s - loss: 2.0170\n",
      "Epoch 00012: loss improved from 2.04092 to 2.01698, saving model to weights-improvement-12-2.0170-256.hdf5\n",
      "31387/31387 [==============================] - 763s 24ms/step - loss: 2.0170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd1c052668>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=12, batch_size=8, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-01-2.7781-256.hdf5\" \n",
    "model.load_weights(filename) \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\"  monstrous big. so, you see.\" he snapped it on. \"montag,\" the tv set said, and\n",
      "l \"\n",
      "'o'\n",
      "' '\n",
      "'t'\n",
      "'h'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'a'\n",
      "'a'\n",
      "'d'\n",
      "' '\n",
      "' '\n",
      "'\"'\n",
      "'n'\n",
      "'o'\n",
      "' '\n",
      "'t'\n",
      "' '\n",
      "'s'\n",
      "'o'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "' '\n",
      "'t'\n",
      "'o'\n",
      "'e'\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\") # generate characters\n",
    "for i in range(1000):\n",
    "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "  x = x / float(n_vocab)\n",
    "  prediction = model.predict(x, verbose=0)\n",
    "  index = numpy.argmax(prediction)\n",
    "  result = int_to_char[index]\n",
    "  seq_in = [int_to_char[value] for value in pattern]\n",
    "  pprint(result)\n",
    "  pattern.append(index)\n",
    "  pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
