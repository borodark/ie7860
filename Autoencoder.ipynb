{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Input,Dense,Flatten,Dropout,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(28 * 28 * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, 28,28)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_data('train-images-idx3-ubyte.gz', 60000)\n",
    "test_data = extract_data('t10k-images-idx3-ubyte.gz', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = extract_labels('train-labels-idx1-ubyte.gz',60000)\n",
    "test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (60000, 28, 28)\n",
      "Test set (images) shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=train_data.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '(Label: E)')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'A',\n",
    " 1: 'B',\n",
    " 2: 'C',\n",
    " 3: 'D',\n",
    " 4: 'E',\n",
    " 5: 'F',\n",
    " 6: 'G',\n",
    " 7: 'H',\n",
    " 8: 'I',\n",
    " 9: 'J',\n",
    "}\n",
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(train_data[10], (28,28))\n",
    "curr_lbl = train_labels[10]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(test_data[10], (28,28))\n",
    "curr_lbl = test_labels[10]\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.reshape(-1, 28,28, 1)\n",
    "test_data = test_data.reshape(-1, 28,28, 1)\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtype, test_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255.0, 255.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / np.max(train_data)\n",
    "test_data = test_data / np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_data), np.max(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,\n",
    "                                                             train_data,\n",
    "                                                             test_size=0.2,\n",
    "                                                             random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "inChannel = 1\n",
    "x, y = 28, 28\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "num_classes = 10\n",
    "def encoder(input_img):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    return conv4\n",
    "\n",
    "def decoder(conv4):    \n",
    "    #decoder\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_img, decoder(encoder(input_img)))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 7, 7, 128)         295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 7, 7, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 1,758,657\n",
      "Trainable params: 1,755,841\n",
      "Non-trainable params: 2,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "750/750 [==============================] - 76s 101ms/step - loss: 0.0191 - val_loss: 0.0118\n",
      "Epoch 2/200\n",
      "108/750 [===>..........................] - ETA: 57s - loss: 0.0123"
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(200)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
